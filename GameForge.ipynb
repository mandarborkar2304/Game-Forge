{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Analysis and Preprocessing"
      ],
      "metadata": {
        "id": "SBybCdHncfKK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnHS_HFVbh1x",
        "outputId": "d380d152-1bfd-40ab-ddf7-6cd29c6c6a08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "data = pd.read_excel('AI_data.xlsx')\n",
        "training_text = data['MECHANIC'] + ' ' + data['OBJECTIVE OF THE GAME'] + ' ' + data['USP'] + ' ' + data['RULES OF THE GAME']\n",
        "training_text_list = training_text.tolist()\n",
        "\n",
        "with open('training_text.txt', 'w') as file:\n",
        "    file.write('\\n'.join(training_text_list))\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Set eos_token as the pad_token\n",
        "input_ids = tokenizer(training_text_list, return_tensors='pt', padding=True, truncation=True)['input_ids']\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning GPT-2 Model"
      ],
      "metadata": {
        "id": "-IdoscmwcoNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "data = pd.read_excel('AI_data.xlsx')\n",
        "training_text = data['MECHANIC'] + ' ' + data['OBJECTIVE OF THE GAME'] + ' ' + data['USP'] + ' ' + data['RULES OF THE GAME']\n",
        "training_text_list = training_text.tolist()\n",
        "\n",
        "with open('training_text.txt', 'w') as file:\n",
        "    file.write('\\n'.join(training_text_list))\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "input_ids = tokenizer(training_text_list, return_tensors='pt', padding=True, truncation=True)['input_ids']\n",
        "config = GPT2Config.from_pretrained('gpt2')\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2', config=config)\n",
        "\n",
        "train_dataset = TextDataset(\n",
        "    tokenizer=tokenizer,\n",
        "    file_path='training_text.txt',\n",
        "    block_size=128,\n",
        ")\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2-fine-tuned\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=4,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        ")\n",
        "trainer.train()\n",
        "model.save_pretrained(\"./gpt2-fine-tuned\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "llANVrSUcPxB",
        "outputId": "35d518a6-03a4-4b24-f5a9-496d25da6e65"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 04:18, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Generation (GAN)"
      ],
      "metadata": {
        "id": "h8G5cqdic9gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "import io\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "def load_pdf_images(pdf_path, target_shape=(64, 64, 3)):\n",
        "    pdf_images = []\n",
        "\n",
        "    pdf_document = fitz.open(pdf_path)\n",
        "\n",
        "    for page_num in range(pdf_document.page_count):\n",
        "        page = pdf_document[page_num]\n",
        "        image_list = page.get_images(full=True)\n",
        "\n",
        "        for img_index, img_info in enumerate(image_list):\n",
        "            img_index = img_info[0]\n",
        "            img_base = pdf_document.extract_image(img_index)\n",
        "            img_bytes = img_base[\"image\"]\n",
        "\n",
        "            image = Image.open(io.BytesIO(img_bytes))\n",
        "            preprocessed_image = image.resize(target_shape[:-1])  # Resize to target shape\n",
        "            preprocessed_image = np.array(preprocessed_image) / 255.0  # Normalize\n",
        "            pdf_images.append(preprocessed_image)\n",
        "\n",
        "    return np.array(pdf_images)"
      ],
      "metadata": {
        "id": "ddY3oAcpFE-s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import layers\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import io\n",
        "import fitz\n",
        "\n",
        "def load_pdf_images(pdf_path, target_shape=(64, 64, 3)):\n",
        "    pdf_images = []\n",
        "\n",
        "    pdf_document = fitz.open(pdf_path)\n",
        "\n",
        "    for page_num in range(pdf_document.page_count):\n",
        "        page = pdf_document[page_num]\n",
        "        image_list = page.get_images(full=True)\n",
        "\n",
        "        for img_index, img_info in enumerate(image_list):\n",
        "            img_index = img_info[0]\n",
        "            img_base = pdf_document.extract_image(img_index)\n",
        "            img_bytes = img_base[\"image\"]\n",
        "\n",
        "            image = Image.open(io.BytesIO(img_bytes))\n",
        "            preprocessed_image = image.resize(target_shape[:-1])  # Resize to target shape\n",
        "            preprocessed_image = np.array(preprocessed_image) / 255.0  # Normalize\n",
        "            pdf_images.append(preprocessed_image)\n",
        "\n",
        "    return np.array(pdf_images)\n",
        "\n",
        "def combine_data(excel_data, pdf_images):\n",
        "    pdf_images_flat = pdf_images.reshape(pdf_images.shape[0], -1)\n",
        "    combined_data = pd.concat([excel_data, pd.DataFrame(pdf_images_flat)], axis=1)\n",
        "    return combined_data\n",
        "\n",
        "latent_dim_gan = 100\n",
        "img_shape_gan = (64, 64, 3)\n",
        "channels_gan = 3\n",
        "excel_path_gan = \"/content/AI_data.xlsx\"\n",
        "pdf_path_gan = \"/content/excel_task_game_images.pdf\"\n",
        "model_dir_gan = \"/content/saved_model\"\n",
        "\n",
        "def load_excel_data(excel_path):\n",
        "    excel_data = pd.read_excel(excel_path)\n",
        "    return excel_data\n",
        "\n",
        "excel_data_gan = load_excel_data(excel_path_gan)\n",
        "pdf_images_gan = load_pdf_images(pdf_path_gan, target_shape=img_shape_gan)\n",
        "combined_data_gan = combine_data(excel_data_gan, pdf_images_gan)\n",
        "pdf_images_gan = pdf_images_gan[:430272]\n",
        "pdf_images_gan = pdf_images_gan.reshape(-1, 64, 64, 3)\n",
        "\n",
        "def preprocess_image(image):\n",
        "    image = image.resize((64, 64))\n",
        "    image = np.array(image) / 255.0\n",
        "    return image\n",
        "\n",
        "def build_generator(latent_dim, channels):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(7 * 7 * 128, input_dim=latent_dim))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Reshape((7, 7, 128)))\n",
        "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Conv2DTranspose(channels, (4, 4), activation='sigmoid', padding='same'))\n",
        "    return model\n",
        "\n",
        "def build_discriminator(img_shape):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same', input_shape=img_shape))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "def build_gan(generator, discriminator):\n",
        "    discriminator.trainable = False\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(generator)\n",
        "    model.add(discriminator)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "    return model\n",
        "\n",
        "def train_gan(generator, discriminator, gan, combined_data, epochs=10, batch_size=32):\n",
        "    X = combined_data.iloc[:, 1:].to_numpy()\n",
        "    y = combined_data.iloc\n"
      ],
      "metadata": {
        "id": "WoEuGl6xfDOl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Ideas"
      ],
      "metadata": {
        "id": "dLpA8P3IdjEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generated_ideas = []\n",
        "for _ in range(5):\n",
        "    seed = training_text.sample().values[0]\n",
        "    generated_text = model.generate(tokenizer(seed, return_tensors='pt')['input_ids'], max_length=200, num_return_sequences=1, no_repeat_ngram_size=2, top_k=50, top_p=0.95)\n",
        "    generated_idea = tokenizer.decode(generated_text[0], skip_special_tokens=True)\n",
        "    generated_ideas.append(generated_idea)\n",
        "\n",
        "generated_ideas_df = pd.DataFrame({'Generated Ideas': generated_ideas})\n",
        "generated_ideas_df.to_csv('generated_ideas.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Ci-LSIadhmh",
        "outputId": "ae45b565-4a3f-43ec-a5bd-7e97ae4febfb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1363: UserWarning: Input length of input_ids is 280, but `max_length` is set to 200. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
            "  warnings.warn(\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDF with Game Ideas and Images"
      ],
      "metadata": {
        "id": "B6m4YmqKcw45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_ideas_df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubzxoBhTY_h7",
        "outputId": "406ac5ad-881a-46ee-be2e-5ebb46f54a13"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Generated Ideas'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fpdf import FPDF\n",
        "import fitz\n",
        "import io\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def extract_images_from_pdf(pdf_path):\n",
        "    pdf_images = []\n",
        "    pdf_document = fitz.open(pdf_path)\n",
        "    for page_num in range(pdf_document.page_count):\n",
        "        page = pdf_document[page_num]\n",
        "        image_list = page.get_images(full=True)\n",
        "\n",
        "        for img_index, img_info in enumerate(image_list):\n",
        "            img_index = img_info[0]\n",
        "            img_base = pdf_document.extract_image(img_index)\n",
        "            img_bytes = img_base[\"image\"]\n",
        "\n",
        "            image = Image.open(io.BytesIO(img_bytes))\n",
        "            pdf_images.append(np.array(image))\n",
        "\n",
        "    return pdf_images\n",
        "\n",
        "def create_pdf_with_images(ideas, images, output_path=\"game_ideas.pdf\"):\n",
        "    pdf = FPDF()\n",
        "    for i, (idea, img_array) in enumerate(zip(ideas, images), start=1):\n",
        "        pdf.add_page()\n",
        "        pdf.set_font(\"Arial\", size=12)\n",
        "        pdf.cell(200, 10, txt=f\"Idea {i}:\", ln=True, align='L')\n",
        "        pdf.multi_cell(0, 10, txt=idea)\n",
        "        pdf.ln(10)\n",
        "        pdf.image(Image.fromarray((img_array * 255).astype(np.uint8)), x=None, y=None, w=150)\n",
        "    pdf.output(output_path)\n",
        "\n",
        "csv_path = \"/content/generated_ideas.csv\"\n",
        "generated_ideas_df = pd.read_csv(csv_path)\n",
        "generated_ideas = generated_ideas_df[\"Generated Ideas\"].tolist()\n",
        "\n",
        "pdf_path = \"/content/excel_task_game_images.pdf\"\n",
        "extracted_images = extract_images_from_pdf(pdf_path)\n",
        "create_pdf_with_images(generated_ideas, extracted_images)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4ZetIp0cTgb",
        "outputId": "6b08b6b3-a344-4657-f7c7-d1a3ad9a4e5e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-592b2de9cd1b>:34: UserWarning: Substituting font arial by core font helvetica\n",
            "  pdf.set_font(\"Arial\", size=12)\n",
            "<ipython-input-19-592b2de9cd1b>:35: DeprecationWarning: The parameter \"txt\" has been renamed to \"text\" in 2.7.6\n",
            "  pdf.cell(200, 10, txt=f\"Idea {i}:\", ln=True, align='L')\n",
            "<ipython-input-19-592b2de9cd1b>:35: DeprecationWarning: The parameter \"ln\" is deprecated since v2.5.2. Instead of ln=True use new_x=XPos.LMARGIN, new_y=YPos.NEXT.\n",
            "  pdf.cell(200, 10, txt=f\"Idea {i}:\", ln=True, align='L')\n",
            "<ipython-input-19-592b2de9cd1b>:36: DeprecationWarning: The parameter \"txt\" has been renamed to \"text\" in 2.7.6\n",
            "  pdf.multi_cell(0, 10, txt=idea)\n"
          ]
        }
      ]
    }
  ]
}